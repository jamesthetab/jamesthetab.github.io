<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Predicting Body Fat Percentage</title>
  <meta name="description" content="In order to highlight some of the power of the Jupyter Notebook I take some analysis performed by Mat Leonard (course developer at Udacity) on his blog and c...">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://jamesthetab.github.io/jekyll/update/2016/08/10/Predicting-Body-Fat-Percentage.html">
  <link rel="alternate" type="application/rss+xml" title="J. S. Cooper - A Curious Mathematician" href="http://jamesthetab.github.io/feed.xml">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">J. S. Cooper - A Curious Mathematician</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Predicting Body Fat Percentage</h1>
    <p class="post-meta"><time datetime="2016-08-10T20:19:28+01:00" itemprop="datePublished">Aug 10, 2016</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>In order to highlight some of the power of the Jupyter Notebook I take some analysis performed by Mat Leonard (course developer at Udacity) on his <a href="http://matatat.org/pages/about.html">blog</a> and converted to .ipynb worksheet adding commentary.</p>

<h2 id="background">Background</h2>

<p>For the past few months, I’ve been commuting to work on my bicycle. I’ve always been a walker, but I’ve been out of shape and slowly gaining fat for some time now. The new activity has led to some obvious weight loss. This has inspired me to keep working at it and track my progress. As part of this, I wanted to measure my percent body fat using tools I have around my apartment. You can find calculators out on the internet which give you a singular estimate. Being a scientist though, I want some knowledge of the uncertainty of the estimate. I decided to build my own model from data which I can use to get an estimate, with the uncertainty, of my body fat percentage.</p>

<p>I found data from a study which measured the body density and various anatomical measurements (such as neck and chest circumferences) of a group of men. From my research, I found that body density can be measured accurately using water or air displacement. However, it is unclear how to convert density into body fat percentage because you must assume a distribution of lean and fatty tissues. There are more than a few methods, but for this analysis I’m going to use Brozek’s method.</p>

<h2 id="importing-packages">Importing Packages</h2>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="o">%</span><span class="n">config</span> <span class="n">InlineBackend</span><span class="o">.</span><span class="n">figure_format</span> <span class="o">=</span> <span class="s">'retina'</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sb</span>
<span class="n">sb</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s">"notebook"</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.25</span><span class="p">)</span>
</code></pre>
</div>

<h2 id="reading-data">Reading Data</h2>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'fat.dat.txt'</span><span class="p">,</span> <span class="n">delim_whitespace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'case'</span><span class="p">,</span> <span class="s">'pbf_b'</span><span class="p">,</span> <span class="s">'pbf_s'</span><span class="p">,</span> <span class="s">'density'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">,</span> <span class="s">'weight'</span><span class="p">,</span> 
                <span class="s">'height'</span><span class="p">,</span> <span class="s">'bmi'</span><span class="p">,</span><span class="s">'fat_free_w'</span><span class="p">,</span> <span class="s">'neck'</span><span class="p">,</span> <span class="s">'chest'</span><span class="p">,</span> <span class="s">'abdomen'</span><span class="p">,</span> 
                <span class="s">'hip'</span><span class="p">,</span> <span class="s">'thigh'</span><span class="p">,</span> <span class="s">'knee'</span><span class="p">,</span> <span class="s">'ankle'</span><span class="p">,</span><span class="s">'biceps'</span><span class="p">,</span> <span class="s">'forearm'</span><span class="p">,</span> <span class="s">'wrist'</span><span class="p">]</span>
<span class="n">data</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'case'</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'case'</span><span class="p">,</span> <span class="s">'fat_free_w'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c"># Remove a few data points (outliers, incorrect values)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="mi">42</span><span class="p">,</span> <span class="mi">182</span><span class="p">])</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'weight'</span><span class="p">]</span><span class="o">&lt;</span><span class="mi">300</span><span class="p">]</span>
</code></pre>
</div>

<p>Now that the data is loaded, we can check it out. We’ll look at the first few cases, then make some plots so we can see how some of the data is distributed. The first two columns are percent body fat (PBF) using the Brozek and Siri formula’s, respectively. Every column from “neck” on is the circumference at those locations.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre>
</div>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pbf_b</th>
      <th>pbf_s</th>
      <th>density</th>
      <th>age</th>
      <th>weight</th>
      <th>height</th>
      <th>bmi</th>
      <th>neck</th>
      <th>chest</th>
      <th>abdomen</th>
      <th>hip</th>
      <th>thigh</th>
      <th>knee</th>
      <th>ankle</th>
      <th>biceps</th>
      <th>forearm</th>
      <th>wrist</th>
    </tr>
    <tr>
      <th>case</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>12.6</td>
      <td>12.3</td>
      <td>1.0708</td>
      <td>23</td>
      <td>154.25</td>
      <td>67.75</td>
      <td>23.7</td>
      <td>36.2</td>
      <td>93.1</td>
      <td>85.2</td>
      <td>94.5</td>
      <td>59.0</td>
      <td>37.3</td>
      <td>21.9</td>
      <td>32.0</td>
      <td>27.4</td>
      <td>17.1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>6.9</td>
      <td>6.1</td>
      <td>1.0853</td>
      <td>22</td>
      <td>173.25</td>
      <td>72.25</td>
      <td>23.4</td>
      <td>38.5</td>
      <td>93.6</td>
      <td>83.0</td>
      <td>98.7</td>
      <td>58.7</td>
      <td>37.3</td>
      <td>23.4</td>
      <td>30.5</td>
      <td>28.9</td>
      <td>18.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>24.6</td>
      <td>25.3</td>
      <td>1.0414</td>
      <td>22</td>
      <td>154.00</td>
      <td>66.25</td>
      <td>24.7</td>
      <td>34.0</td>
      <td>95.8</td>
      <td>87.9</td>
      <td>99.2</td>
      <td>59.6</td>
      <td>38.9</td>
      <td>24.0</td>
      <td>28.8</td>
      <td>25.2</td>
      <td>16.6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>10.9</td>
      <td>10.4</td>
      <td>1.0751</td>
      <td>26</td>
      <td>184.75</td>
      <td>72.25</td>
      <td>24.9</td>
      <td>37.4</td>
      <td>101.8</td>
      <td>86.4</td>
      <td>101.2</td>
      <td>60.1</td>
      <td>37.3</td>
      <td>22.8</td>
      <td>32.4</td>
      <td>29.4</td>
      <td>18.2</td>
    </tr>
    <tr>
      <th>5</th>
      <td>27.8</td>
      <td>28.7</td>
      <td>1.0340</td>
      <td>24</td>
      <td>184.25</td>
      <td>71.25</td>
      <td>25.6</td>
      <td>34.4</td>
      <td>97.3</td>
      <td>100.0</td>
      <td>101.9</td>
      <td>63.2</td>
      <td>42.2</td>
      <td>24.0</td>
      <td>32.2</td>
      <td>27.7</td>
      <td>17.7</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="exploring-basic-pairwise-trends">Exploring Basic Pairwise Trends</h2>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">sb</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data</span><span class="p">[[</span><span class="s">'pbf_b'</span><span class="p">,</span> <span class="s">'bmi'</span><span class="p">,</span> <span class="s">'wrist'</span><span class="p">,</span> <span class="s">'abdomen'</span><span class="p">]],</span> 
                 <span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">plot_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'s'</span><span class="p">:</span><span class="mi">15</span><span class="p">,</span><span class="s">'edgecolor'</span><span class="p">:</span><span class="s">'none'</span><span class="p">,</span><span class="s">'alpha'</span><span class="p">:</span><span class="mf">0.7</span><span class="p">})</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>&lt;seaborn.axisgrid.PairGrid at 0x11432e690&gt;
</code></pre>
</div>

<p><img src="/assets/output_7_1.png" alt="png" /></p>

<p>From this we can see the percent body fat is correlated with weight and body measurements, while height has little if any effect. There are also correlations between body measurements and weight which we’ll have to deal with later. I’m going to use a linear regression model to predict percent body fat from the data.</p>

<p>A linear regression model is a formal way to draw a line through a set of data points. For instance, we can see that when we plot abdomen circumference on the \(x\)-axis and percent body fat on the \(y\)-axis (first row, fifth column), the data falls along a general upward sloped line. As we would expect, a larger gut indicates more body fat. We can get a decent estimate of this relationship by printing out the plot and drawing a line through the data points by hand. However, we want to find the “best” line. What I mean by “best” is that the line we draw has the least error predicting the existing data points.</p>

<p>We can define any line using an intercept, \(\beta_0\), and a slope, \(\beta_1\), as <script type="math/tex">y = \beta_0 + \beta_1 x</script>.</p>

<p>Here, \(y\) is our dependent variable, percent body fat for example, and \(x\) is the independent variable, such as abdomen circumference. Depending on the context and conventions, \(x\) is also called the explanatory variable, regressor, feature, predictor, and more. Our model is a prediction of the percent body fat \(\hat y\) using the abdomen circumference \(x\).</p>

<script type="math/tex; mode=display">\hat y_i = \beta_0 + \beta_1 x_i</script>

<p>where the subscript \(i\) indicates which data point we are using (\(i=1\) is the first data point, and so on). Our goal here is to find values for \(\beta_0\) and \(\beta_1\) which give us the smallest error \(\epsilon_i = y_i - \hat y_i\).</p>

<p>We find an exact solution to this problem if we minimize the sum of the squares of the errors,</p>

<script type="math/tex; mode=display">SSE=\sum_{i=1}^n \vert y_i−\hat y_i \vert^2</script>

<p>We do this using the ordinary least squares method. Here I will use the excellent <code class="highlighter-rouge">scikits</code> learn Python package to fit a linear model to our data.</p>

<h2 id="least-squares">Least Squares</h2>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">features</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s">'abdomen'</span><span class="p">]]</span>

<span class="c"># Make an intercept column that is all 1</span>
<span class="n">features</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="s">'intercept'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)),</span> <span class="n">index</span><span class="o">=</span><span class="n">features</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

<span class="c"># This is the part that fits the linear model to the data</span>
<span class="n">linmodel</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">linmodel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">'pbf_b'</span><span class="p">])</span>

</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c"># And here I'll calculate the variances and print our results</span>
<span class="n">var_e</span> <span class="o">=</span> <span class="n">linmodel</span><span class="o">.</span><span class="n">residues_</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>
<span class="n">var_b</span> <span class="o">=</span> <span class="n">var_e</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">features</span><span class="p">))</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Coefficients and standard dev."</span><span class="p">)</span>
<span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">coef</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">linmodel</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">var_b</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'{}: {:.3f} +</span><span class="err">\</span><span class="s">- {:.3f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">coef</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">)))</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>Coefficients and standard dev.
abdomen: 0.616 +\- 0.027
intercept: -37.991 +\- 2.541
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">color</span> <span class="o">=</span> <span class="n">sb</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s">'deep'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">left</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[[</span><span class="s">'abdomen'</span><span class="p">]],</span> <span class="n">data</span><span class="p">[[</span><span class="s">'pbf_b'</span><span class="p">]],</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Data'</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="mi">130</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">left</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">linmodel</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">linmodel</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="s">'-r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Model'</span><span class="p">)</span>
<span class="n">left</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Abdomen circumference (cm)"</span><span class="p">)</span>
<span class="n">left</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Percent body fat"</span><span class="p">)</span>
<span class="n">left</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'best'</span><span class="p">)</span>

<span class="n">y_hat</span> <span class="o">=</span> <span class="n">linmodel</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">linmodel</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">data</span><span class="p">[[</span><span class="s">'abdomen'</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s">'pbf_b'</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">y_hat</span>
<span class="n">right</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[[</span><span class="s">'abdomen'</span><span class="p">]],</span> <span class="n">residuals</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
<span class="n">right</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Residuals"</span><span class="p">)</span>
<span class="n">_</span><span class="o">=</span><span class="n">right</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Abdomen circumference (cm)"</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre>
</div>

<p><img src="/assets/output_14_0.png" alt="png" /></p>

<p>We see here that our model fits the data pretty well, but I’d like to measure the quality of the fit. A common way to measure the performance of the model is to split the data into a training set and a testing set. You fit the model to the training set, then measure how well it can predict the test set. This is known as cross-validation (CV) and is sort of the industry standard. I’ll use <code class="highlighter-rouge">scikits learn</code> to perform \(k\)-folds CV. This method separates the data into \(k\) parts (folds). Then, it uses \(k−1\) folds to fit the model and then tests the model on the left out fold. Repeat this \(k\) times using each fold to test only once.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">linmodel</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s">'pbf_b'</span><span class="p">],</span>
                         <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'mean_absolute_error'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Mean absolute error: {:.3f}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">-</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>Mean absolute error: 3.620
</code></pre>
</div>

<h2 id="multi-variable-model">Multi-Variable Model</h2>

<p>We can improve our model by including all the information we have in the data. Using a linear model makes this simple, we just add more coefficients. For each data point we have \(m\) features and we can use them to predict the body fat percentage \(\hat y\):</p>

<script type="math/tex; mode=display">\hat y_i = \beta_0 + \beta_1 x_i + \beta_2 x_i +\dots + \beta_m x_i = \sum_{i=1}^m \beta_j x_j</script>

<p>where the subscript \(j\) indicates our data features and \(x_0=1\).</p>

<p>For convenience, we can write our model in matrix notation: <script type="math/tex">\hat y = \mathbf X \beta</script>.</p>

<script type="math/tex; mode=display">% <![CDATA[
\hat y = 
\left(
\begin{array}{c}
  y_1  \\
  y_2   \\
  \vdots \\
  y_n
\end{array}
\right)
\,\,\,\,\,
\beta = 
\left(
\begin{array}{c}
  \beta_1  \\
  \beta_2   \\
  \vdots \\
  \beta_n
\end{array}
\right)
\,\,\,\,\,
\mathbf{X} =
\left(
\begin{array}{ccccc}
1  & x_{1,1}  & x_{1,2} & \dots& x_{1,m}\\
1  & x_{2,1}  & x_{2,2} &  \dots & x_{2,m}\\
1  & \vdots & \vdots &  &\vdots \\
1  & x_{n,1}  & x_{n,2} & \dots & x_{m,n} 
\end{array}
\right) %]]></script>

<p>Again, our error is 
<script type="math/tex">\mathbf{\epsilon} = \sum_{i=1}^{n} \left|\, y_i - \hat{y}_i \right|^2</script> 
which we want to minimize. There is an exact and unique solution for the coefficients that minimize the error:</p>

<script type="math/tex; mode=display">\hat \beta = (X^TX)^{-1}X^Ty</script>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">features</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s">'height'</span><span class="p">,</span> <span class="s">'weight'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">,</span> <span class="s">'neck'</span><span class="p">,</span> <span class="s">'chest'</span><span class="p">,</span> <span class="s">'abdomen'</span><span class="p">,</span> 
                 <span class="s">'hip'</span><span class="p">,</span> <span class="s">'thigh'</span><span class="p">,</span> <span class="s">'knee'</span><span class="p">,</span> <span class="s">'ankle'</span><span class="p">,</span><span class="s">'biceps'</span><span class="p">,</span> <span class="s">'forearm'</span><span class="p">,</span> 
                 <span class="s">'wrist'</span><span class="p">]]</span>
<span class="n">features</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="s">'intercept'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)),</span> 
                                        <span class="n">index</span><span class="o">=</span><span class="n">features</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">linmodel</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">linmodel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">'pbf_b'</span><span class="p">])</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">linmodel</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s">'pbf_b'</span><span class="p">],</span>
                         <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'mean_absolute_error'</span><span class="p">)</span>
<span class="n">var_e</span> <span class="o">=</span> <span class="n">linmodel</span><span class="o">.</span><span class="n">residues_</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.</span><span class="p">)</span>
<span class="n">var_b</span> <span class="o">=</span> <span class="n">var_e</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">features</span><span class="p">))</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Coefficients and standard dev."</span><span class="p">)</span>
<span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">coef</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">linmodel</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">var_b</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'{}: {:.3f} +</span><span class="err">\</span><span class="s">- {:.3f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">coef</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Mean absolute error: {:.3f}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">-</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>Coefficients and standard dev.
height: -0.248 +\- 0.178
weight: -0.006 +\- 0.063
age: 0.065 +\- 0.030
neck: -0.355 +\- 0.218
chest: -0.132 +\- 0.101
abdomen: 0.839 +\- 0.085
hip: -0.157 +\- 0.135
thigh: 0.151 +\- 0.137
knee: -0.070 +\- 0.227
ankle: 0.161 +\- 0.204
biceps: 0.164 +\- 0.158
forearm: 0.250 +\- 0.192
wrist: -1.663 +\- 0.494
intercept: 7.259 +\- 21.873
Mean absolute error: 3.353
</code></pre>
</div>

<p>Since we know that many of our features are correlated, we can use ridge regression to obtain a better prediction. Ridge regression is similar to normal linear regression, but we add a term to the error function that penalizes the size of the coefficients,</p>

<script type="math/tex; mode=display">\epsilon = \sum_{i=1}^n \vert y_i− \hat y_i \vert^2 + \lambda \sum_j^m\beta^2_j</script>

<p>The penalty pulls the coefficients towards zero, a process known as shrinkage, and decreases the variance in the model, leading towards better predictions. The amount of shrinkage is controlled by the parameter \(\lambda\), as \(\lambda \rightarrow \infty\) all coefficients go to zero, and as \(\lambda \rightarrow 0\) we get our normal linear regression. However, there is no way to know before hand what the best value for \(\lambda\) is. I can find the best \(\lambda\) by fitting a bunch of models with different \(\lambda\) and choose the one with the least prediction error. This is typically done with (again) cross-validation and is available from <code class="highlighter-rouge">scikits-learn</code>.</p>

<p>I’ll also need to scale the features so that all the coefficients are on the same scale, and center the dependent variable as well.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">scaled_features</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'pbf_b'</span><span class="p">]</span><span class="o">-</span><span class="n">data</span><span class="p">[</span><span class="s">'pbf_b'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="n">ridge</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">100</span><span class="p">),</span> 
                             <span class="n">fit_intercept</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">ridge</span><span class="p">,</span> <span class="n">scaled_features</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
                         <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'mean_absolute_error'</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Coefficients"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">coef</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">var_b</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'{}: {:.3f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">coef</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Mean absolute error: {:.3f}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">-</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>Coefficients
height: -0.736
weight: 0.094
age: 0.908
neck: -0.781
chest: -0.822
abdomen: 7.843
hip: -0.759
thigh: 0.717
knee: -0.153
ankle: 0.231
biceps: 0.430
forearm: 0.461
wrist: -1.529
intercept: 0.000
Mean absolute error: 3.302
</code></pre>
</div>

<p>Using ridge regression does improve our model a bit. However, I don’t want to have to measure ten things every time I want to calculate my body fat. What I would like to do is find a small number of features that still give me a good prediction. A good method for this is lasso regression which is similar to ridge regression in that it penalizes the size of the coefficients, but instead of simply shrinking them, it sets coefficients to exactly zero. Here the error function is</p>

<script type="math/tex; mode=display">\epsilon = \sum_{i=1}^n \vert y_i− \hat y_i \vert^2 + \lambda \sum_j^m\beta^2_j</script>

<p>We can see how the coefficients start at \(0\) for large \(\lambda\), then become non-zero as \(\lambda\) is decreased.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">features</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s">'height'</span><span class="p">,</span> <span class="s">'weight'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">,</span> <span class="s">'neck'</span><span class="p">,</span> <span class="s">'chest'</span><span class="p">,</span> <span class="s">'abdomen'</span><span class="p">,</span> 
                 <span class="s">'hip'</span><span class="p">,</span> <span class="s">'thigh'</span><span class="p">,</span> <span class="s">'knee'</span><span class="p">,</span> <span class="s">'ankle'</span><span class="p">,</span> <span class="s">'biceps'</span><span class="p">,</span> <span class="s">'forearm'</span><span class="p">,</span> 
                 <span class="s">'wrist'</span><span class="p">]]</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> 
                        <span class="n">index</span><span class="o">=</span><span class="n">features</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">features</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'pbf_b'</span><span class="p">]</span><span class="o">-</span><span class="n">data</span><span class="p">[</span><span class="s">'pbf_b'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="n">lambdas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">features</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">lambdas</span><span class="p">)</span>
<span class="k">for</span> <span class="n">each</span> <span class="ow">in</span> <span class="n">lambdas</span><span class="p">:</span>
    <span class="n">lasso</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">each</span><span class="p">)</span>
    <span class="n">lasso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="n">each</span><span class="p">]</span> <span class="o">=</span> <span class="n">lasso</span><span class="o">.</span><span class="n">coef_</span>
<span class="n">df</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s">'-'</span><span class="p">,</span> <span class="n">logx</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">colormap</span><span class="o">=</span><span class="s">'Paired'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'$</span><span class="err">\</span><span class="s">lambda$'</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'coefficient'</span><span class="p">)</span>
</code></pre>
</div>

<p><img src="/assets/output_26_0.png" alt="png" /></p>

<p>We can see here that abdomen circumference is always a strong predictor. As \(\lambda\) gets smaller, the coefficient for height becomes non-zero, then wrist circumference and age. I’m going to use these four features for my final model. It is reasonable that height and wrist circumference are negatively related to percent body fat. They indicate how long and how thick your bones are, respectively. Also, it seems that as one gets older, the percent body fat increases, holding everything else constant. I’m guessing this is from a change in the distribution of tissues, younger men having more muscle than older men. Now we can build a simpler model using only these features.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">features</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s">'height'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">,</span> <span class="s">'abdomen'</span><span class="p">,</span> <span class="s">'wrist'</span><span class="p">]]</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> 
                        <span class="n">index</span><span class="o">=</span><span class="n">features</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">features</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'pbf_b'</span><span class="p">]</span><span class="o">-</span><span class="n">data</span><span class="p">[</span><span class="s">'pbf_b'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">fit_intercept</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">ridge</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
                         <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'mean_absolute_error'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'{}: {:.3f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">coef</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Mean abs error: {:.3f}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">-</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>height: -0.794
age: 0.639
abdomen: 7.117
wrist: -1.571
Mean abs error: 3.291
</code></pre>
</div>

<h2 id="prediction">Prediction</h2>

<p>Finally, I can predict my own body fat percentage. I’ll use the CV error previously calculated as an estimate of the uncertainty.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">measurements</span> <span class="o">=</span> <span class="p">[</span><span class="mi">71</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">88</span><span class="p">,</span> <span class="mf">17.5</span><span class="p">]</span>
<span class="n">scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">measurements</span><span class="p">)</span>
<span class="n">my_pbf</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">scaled</span><span class="p">)</span><span class="o">+</span><span class="n">data</span><span class="p">[</span><span class="s">'pbf_b'</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"My PBF = {} +/- {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">my_pbf</span><span class="p">,</span> <span class="o">-</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>My PBF = [ 16.16648387] +/- 3.29132724978
</code></pre>
</div>


  </div>

</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">J. S. Cooper - A Curious Mathematician</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
         
          <li><a href="mailto:jsc42@cantab.net">jsc42@cantab.net</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/jamesthetab"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">jamesthetab</span></a>

          </li>
          

          
          <li>
            <a href="https://www.linkedin.com/in/jamesthetab">
            <span class="icon  icon--twitter">
             <svg viewBox="0 0 61 61">
             <path fill="#828282" d="M49.265,4.667H7.145c-2.016,0-3.651,1.596-3.651,3.563v42.613c0,1.966,1.635,3.562,3.651,3.562h42.12   c2.019,0,3.654-1.597,3.654-3.562V8.23C52.919,6.262,51.283,4.667,49.265,4.667z M18.475,46.304h-7.465V23.845h7.465V46.304z    M14.743,20.777h-0.05c-2.504,0-4.124-1.725-4.124-3.88c0-2.203,1.67-3.88,4.223-3.88c2.554,0,4.125,1.677,4.175,3.88   C18.967,19.052,17.345,20.777,14.743,20.777z M45.394,46.304h-7.465V34.286c0-3.018-1.08-5.078-3.781-5.078   c-2.062,0-3.29,1.389-3.831,2.731c-0.197,0.479-0.245,1.149-0.245,1.821v12.543h-7.465c0,0,0.098-20.354,0-22.459h7.465v3.179   c0.992-1.53,2.766-3.709,6.729-3.709c4.911,0,8.594,3.211,8.594,10.11V46.304z"/>
             </svg>
            </span>
            <span class="username">jamesthetab
            </span>
            </a>
          </li>
          

          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>A place for me to reflect on my experiences of mathematical research, education, coding,  and the search for an engaging career.
</p>
      </div>
    </div>

  </div>

</footer>



  </body>

</html>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
